# Fundamentos Teóricos

O projeto de tradução automática da Língua Brasileira de Sinais (Libras) para a língua portuguesa utilizando visão computacional e inteligência artificial (IA) é um campo interdisciplinar que envolve conhecimentos de linguística, visão computacional, inteligência artificial e sobretudo inclusão social. Esses fundamentos teóricos são essenciais para embasar o desenvolvimento do sistema proposto, garantindo que ele seja tecnicamente viável, culturalmente sensível e socialmente impactante.

Em primeiro lugar, é válido lembrar que a Libras é uma língua visuo-espacial, com estrutura gramatical própria e características únicas que a diferenciam das línguas orais. Diferente do português, que é uma língua oral-auditiva, a Libras utiliza sinalizações, expressões faciais e movimentos corporais para transmitir significados. Por esse motivo, a gramática da Libras inclui aspectos como a configuração das mãos, o ponto de articulação, o movimento e as expressões não manuais (como expressões faciais e movimentos da cabeça). Esses elementos são fundamentais para a comunicação em Libras e devem ser considerados no desenvolvimento do sistema de tradução automática. Além disso, é importante citar que a Libras apresenta variações regionais, o que significa que um mesmo sinal pode ter diferentes significados em diferentes regiões do Brasil. No entanto, apesar desses ultimos pontos, o sistema será capaz de reconhecer e interpretar de inicio sinais básicos da Libras, e assim, desse modo, com a evolução desse sistema, será também capaz futuramente de reconhcer e garantir uma tradução precisa das expressões, variações de regionalismo e, portanto, será culturalmente sensível.

Outrossim, a visão computacional é uma área da ciência da computação que permite que máquinas "vejam" e interpretem imagens e vídeos. Por essa razão, no contexto do projeto, a visão computacional será utilizada para capturar e processar os gestos das mãos e as expressões faciais que compõem os sinais da Libras. Técnicas como filtragem, segmentação e detecção de bordas são usadas para melhorar a qualidade das imagens capturadas, facilitando o reconhecimento dos sinais. Além disso, as redes neurais convolucionais (CNNs) são amplamente utilizadas para reconhecer padrões visuais, como a forma das mãos e a direção dos movimentos. Essas redes são especialmente eficazes para tarefas de reconhecimento de gestos estáticos e dinâmicos, que são essenciais para a tradução automática de Libras.

Ademas, para a inteligência artificial (IA), em particular o aprendizado profundo (deep learning), desempenha um papel crucial no reconhecimento e tradução de línguas de sinais. Então, modelos como **redes neurais recorrentes** (RNNs) e **Transformers** são eficazes para capturar sequências temporais, como gestos dinâmicos que envolvem movimentos ao longo do tempo. As RNNs são especialmente úteis para processar dados sequenciais, como vídeos de sinais, enquanto os Transformers são modelos avançados que têm se mostrado eficientes em tarefas de tradução e processamento de linguagem natural (NLP). Esses modelos podem ser treinados com grandes volumes de dados para reconhecer e traduzir sinais com alta precisão. Além disso, técnicas de processamento de linguagem natural (NLP) podem ser utilizadas para traduzir os sinais capturados em texto ou fala, permitindo que o sistema seja utilizado por ouvintes que não dominam a Libras.

Portanto, com essas tecnologias assistivas, que são ferramentas que ajudam pessoas com deficiência a superar limitações e a participar plenamente da sociedade, o sistema de tradução automática de Libras para o português proposto neste projeto é um exemplo de tecnologia que pode promover a acessibilidade e a inclusão sobretudo nas educação das escolas do ensino médio no Brasil. Por isso, ao facilitar a comunicação entre surdos e ouvintes, o sistema pode melhorar o acesso a serviços essenciais, como além da educação, a saúde e o emprego, reduzindo as barreiras que limitam a participação plena das pessoas surdas na sociedade.








